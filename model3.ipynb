{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ALejandroCh17/Tennis-Ball-Robot/blob/daniel_branch/model3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR_6xG0qLeSH",
        "outputId": "57bf0943-b012-4136-db54-431b4eca49f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create local directories\n",
        "!mkdir -p /content/local_train\n",
        "!mkdir -p /content/local_test\n",
        "!mkdir -p /content/local_valid"
      ],
      "metadata": {
        "id": "V7RO2VZTtHjq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy data\n",
        "!cp -r \"/content/drive/My Drive/capstone_dataset_3/train\" \"/content/local_train\"\n",
        "!cp -r \"/content/drive/My Drive/capstone_dataset_3/test\" \"/content/local_test\"\n",
        "!cp -r \"/content/drive/My Drive/capstone_dataset_3/valid\" \"/content/local_valid\""
      ],
      "metadata": {
        "id": "ufidMrLitasH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# update paths\n",
        "train_images_dir = '/content/local_train/images'\n",
        "train_labels_dir = '/content/local_train/labels'\n",
        "\n",
        "test_images_dir = '/content/local_test/images'\n",
        "test_labels_dir = '/content/local_test/labels'\n",
        "\n",
        "valid_images_dir = '/content/local_valid/images'\n",
        "valid_labels_dir = '/content/local_valid/labels'"
      ],
      "metadata": {
        "id": "pd508cbauHP4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/My Drive/capstone_dataset_3/'\n",
        "\n",
        "train_dir = '/content/drive/My Drive/capstone_dataset_3/train'\n",
        "test_dir = '/content/drive/My Drive/capstone_dataset_3/test'\n",
        "valid_dir = '/content/drive/My Drive/capstone_dataset_3/valid'\n",
        "\n",
        "train_images_dir = '/content/drive/My Drive/capstone_dataset_3/train/images'\n",
        "train_labels_dir = '/content/drive/My Drive/capstone_dataset_3/train/labels'\n",
        "\n",
        "test_images_dir = '/content/drive/My Drive/capstone_dataset_3/test/images'\n",
        "test_labels_dir = '/content/drive/My Drive/capstone_dataset_3/test/labels'\n",
        "\n",
        "valid_images_dir = '/content/drive/My Drive/capstone_dataset_3/valid/images'\n",
        "valid_labels_dir = '/content/drive/My Drive/capstone_dataset_3/valid/labels'\n"
      ],
      "metadata": {
        "id": "qNSExIATBa63"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "YK5K5zpBK4CM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(640, 640, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(5, activation='linear')  # The output layer has 5 nodes corresponding to the class label and bounding box coordinates\n",
        "])"
      ],
      "metadata": {
        "id": "zbKSvULVK9Y2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(lr=1e-4),\n",
        "              loss='mean_squared_error',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "yugp6DOnLElx",
        "outputId": "fd5118aa-6315-43c4-9107-ee371a04ffd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "class BoundingBoxDataGenerator(Sequence):\n",
        "    def __init__(self, images_dir, labels_dir, batch_size, img_size, shuffle=True):\n",
        "        self.images_dir = images_dir\n",
        "        self.labels_dir = labels_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.image_filenames = os.listdir(images_dir)\n",
        "        if shuffle:\n",
        "            np.random.shuffle(self.image_filenames)\n",
        "\n",
        "    def __len__(self):\n",
        "        # Compute the number of batches to produce\n",
        "        return int(np.floor(len(self.image_filenames) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.image_filenames[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [k for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Updates indexes after each epoch\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.image_filenames)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.img_size, 3))\n",
        "        y = np.empty((self.batch_size, 5))  # Assuming one bounding box per image; adjust if more\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store sample\n",
        "            img_path = os.path.join(self.images_dir, ID)\n",
        "            img = load_img(img_path, target_size=self.img_size)\n",
        "            X[i,] = img_to_array(img) / 255.0\n",
        "\n",
        "            # Store class label and bounding box\n",
        "            label_path = os.path.join(self.labels_dir, ID.replace('.jpg', '.txt'))\n",
        "            with open(label_path, 'r') as file:\n",
        "                bounding_box = np.loadtxt(file)\n",
        "                y[i,] = bounding_box[0] if bounding_box.ndim == 1 else bounding_box[0, :]  # Adjust if more bounding boxes\n",
        "\n",
        "        return X, y"
      ],
      "metadata": {
        "id": "zI0koyMzMz0G"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = BoundingBoxDataGenerator(\n",
        "    images_dir=train_images_dir,\n",
        "    labels_dir=train_labels_dir,\n",
        "    batch_size=32,\n",
        "    img_size=(640, 640)  # Adjust based on your needs\n",
        ")"
      ],
      "metadata": {
        "id": "2CQgj8L8M-vR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = BoundingBoxDataGenerator(\n",
        "    images_dir=valid_images_dir,\n",
        "    labels_dir=valid_labels_dir,\n",
        "    batch_size=32,\n",
        "    img_size=(640, 640)  # Replace with the size you're using for your images\n",
        ")"
      ],
      "metadata": {
        "id": "1xB-dx81Nf2I"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_gen, epochs=10, validation_data=validation_generator)"
      ],
      "metadata": {
        "id": "je74H2E-LMqu",
        "outputId": "959bada8-b2f3-424b-a78b-37b31971bac0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "73/73 [==============================] - 40s 446ms/step - loss: 817.5500 - accuracy: 0.4572 - val_loss: 0.0090 - val_accuracy: 0.5063\n",
            "Epoch 2/10\n",
            "73/73 [==============================] - 33s 451ms/step - loss: 0.0335 - accuracy: 0.2800 - val_loss: 0.0092 - val_accuracy: 0.0375\n",
            "Epoch 3/10\n",
            "73/73 [==============================] - 33s 449ms/step - loss: 0.0218 - accuracy: 0.1952 - val_loss: 0.0131 - val_accuracy: 0.0562\n",
            "Epoch 4/10\n",
            "73/73 [==============================] - 33s 452ms/step - loss: 0.0141 - accuracy: 0.2359 - val_loss: 0.0127 - val_accuracy: 0.1125\n",
            "Epoch 5/10\n",
            "73/73 [==============================] - 33s 456ms/step - loss: 0.0106 - accuracy: 0.2753 - val_loss: 0.0158 - val_accuracy: 0.0938\n",
            "Epoch 6/10\n",
            "73/73 [==============================] - 33s 450ms/step - loss: 0.0088 - accuracy: 0.3292 - val_loss: 0.0177 - val_accuracy: 0.1063\n",
            "Epoch 7/10\n",
            "73/73 [==============================] - 33s 449ms/step - loss: 0.0071 - accuracy: 0.3579 - val_loss: 0.0166 - val_accuracy: 0.1187\n",
            "Epoch 8/10\n",
            "73/73 [==============================] - 33s 448ms/step - loss: 0.0059 - accuracy: 0.4204 - val_loss: 0.0164 - val_accuracy: 0.1063\n",
            "Epoch 9/10\n",
            "73/73 [==============================] - 32s 438ms/step - loss: 0.0054 - accuracy: 0.4238 - val_loss: 0.0167 - val_accuracy: 0.0812\n",
            "Epoch 10/10\n",
            "73/73 [==============================] - 32s 440ms/step - loss: 0.0051 - accuracy: 0.4324 - val_loss: 0.0182 - val_accuracy: 0.0812\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7baff79e6ef0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOZwMQ4FvbCCKvbv/Rsiez7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}